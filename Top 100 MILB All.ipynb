{
  "cells": [
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "###Part 1: scraping initial 2019 mlb pipeline json file for player ID dataframe\n!pip install textblob\n\nfrom textblob import TextBlob\n\nimport pandas as pd\n\nimport requests\n\nimport json",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Requirement already satisfied: textblob in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (0.15.3)\r\nRequirement already satisfied: nltk>=3.1 in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from textblob) (3.3)\r\nRequirement already satisfied: six in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from nltk>=3.1->textblob) (1.11.0)\r\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "###2013\n\n###Part 1: scraping initial 2013 mlb pipeline json file for player ID dataframe\n\n#making initial broad datarfame\nmlb_json_id_url_2013 = 'http://m.mlb.com/gen/players/prospects/2013/playerProspects.json'\nresponse_2013 = requests.get(mlb_json_id_url_2013)\nresponse_2013.status_code\nall_json_2013 = response_2013.json()\nprospect_list_2013 = all_json_2013['prospect_players']['prospects']\nplayer_ids_2013 = []\nplayer_ranks_2013 = []\nplayer_first_name_2013 = []\nplayer_last_name_2013 = []\nplayer_position_2013 = []\nplayer_team_2013 = []\nfor i in prospect_list_2013:\n    player_id = str(i['player_id'])\n    player_ids_2013.append(player_id)                      \n    rank = i[\"rank\"]\n    player_ranks_2013.append(rank)\n    first_name = i[\"player_first_name\"]\n    player_first_name_2013.append(first_name)\n    last_name = i[\"player_last_name\"]\n    player_last_name_2013.append(last_name)\n    position = i[\"position\"]\n    player_position_2013.append(position)\n    team = i[\"team_file_code\"]\n    player_team_2013.append(team)\n    player_id_data_2013 = {'First Name' : player_first_name_2013, 'Last Name' : player_last_name_2013, 'Player ID' : player_ids_2013, 'Team' : player_team_2013, 'Position' : player_position_2013, 'Player Rank' : player_ranks_2013}\n\n\nplayer_id_dataframe_2013 = pd.DataFrame(player_id_data_2013)\n\n\n###Part 3: Scraping every Top100 report into dataframes\npipeline_url = \"http://m.mlb.com/gen/players/prospects/2013/\"\nprospect_url_list_2013 = []\nlink_status_2013 = []\n#making links\nfor i in player_ids_2013:\n    prospect_url = pipeline_url + i + '.json'\n    prospect_url_list_2013.append(prospect_url)\n\n#testing links\nfor i in prospect_url_list_2013:    \n    response = requests.get(i)\n    if response.status_code == 200:\n        link = 'Link is working'\n    else:\n        link = 'Link does not work'\n    link_status_2013.append(link)\n    \n#making initial list of player scout-reports/cards\ncard_list_2013 = []\nfor i in prospect_url_list_2013:    \n    response = requests.get(i)\n    player_card_framed = response.json()\n    player_card = player_card_framed['prospect_player']\n    player_card\n    player_report_and_video = player_card['content']\n    player_report = player_report_and_video['default']\n    card_list_2013.append(player_report)\n\n\n\nreport_trim_1_list_2013 = []\nfor i in card_list_2013:\n    trim = i.rfind('Overall: ') + 10\n    report_trim_1 = i[trim:]\n    report_trim_1_list_2013.append(report_trim_1)\n\nreport_cleaner_list_2013 = []\nfor i in report_trim_1_list_2013:\n    start = i.find('<p>') + 3\n    trim_p = i[start:]\n    report_cleaner_list_2013.append(trim_p)\n    \nreport_cleanest_list_2013 = []\nfor i in report_cleaner_list_2013:\n    if i.find('</a>') == -1:\n          end = len(i)\n    else:\n        end = i.find('\\n<p>\\n')\n    trim_a = i[:end]\n    report_cleanest_list_2013.append(trim_a)\n    \nreports_2013 = []\nfor i in report_cleanest_list_2013:\n    without_p = i.replace('<p>', '')\n    without_p2 = without_p.replace('p>', '')\n    without_n = without_p2.replace('\\n', '')\n    without_slash = without_n.replace('/', '')\n    without_tag = without_slash.replace('&#8217;', \"'\")\n    without_tag2 = without_tag.replace(' &#8211;', \",\")\n    without_tag3 = without_tag2.replace('&rsquo;', \"'\")\n    lowered = without_tag3.lower()\n    reports_2013.append(lowered)\n\nplayer_id_dataframe_2013['Written Report'] = reports_2013\ntop_one_hundred_data_2013 = player_id_dataframe_2013\n\nfull_scores = []\n\nfor i in reports_2013:\n    \n    text = TextBlob(i)\n   \n    score = text.sentiment\n    \n    full_scores.append(score)\n\nfull_scores\n\ntop_one_hundred_data_2013['Sentiment Score'] = full_scores\n\nsorted_2013 = top_one_hundred_data_2013.sort_values(by=['Sentiment Score'],ascending = False)\n\n\nsorted_2013 = sorted_2013.drop(['Written Report', 'Player ID'], axis = 1)\n\n\n\n\n###2014\n\n###Part 1: scraping initial 2014 mlb pipeline json file for player ID dataframe\n\n#making initial broad datarfame\nmlb_json_id_url_2014 = 'http://m.mlb.com/gen/players/prospects/2014/playerProspects.json'\nresponse_2014 = requests.get(mlb_json_id_url_2014)\nresponse_2014.status_code\nall_json_2014 = response_2014.json()\nprospect_list_2014 = all_json_2014['prospect_players']['prospects']\nplayer_ids_2014 = []\nplayer_ranks_2014 = []\nplayer_first_name_2014 = []\nplayer_last_name_2014 = []\nplayer_position_2014 = []\nplayer_team_2014 = []\nfor i in prospect_list_2014:\n    player_id = str(i['player_id'])\n    player_ids_2014.append(player_id)                      \n    rank = i[\"rank\"]\n    player_ranks_2014.append(rank)\n    first_name = i[\"player_first_name\"]\n    player_first_name_2014.append(first_name)\n    last_name = i[\"player_last_name\"]\n    player_last_name_2014.append(last_name)\n    position = i[\"position\"]\n    player_position_2014.append(position)\n    team = i[\"team_file_code\"]\n    player_team_2014.append(team)\n    player_id_data_2014 = {'First Name' : player_first_name_2014, 'Last Name' : player_last_name_2014, 'Player ID' : player_ids_2014, 'Team' : player_team_2014, 'Position' : player_position_2014, 'Player Rank' : player_ranks_2014}\n\n\nplayer_id_dataframe_2014 = pd.DataFrame(player_id_data_2014)\n\n\n###Part 3: Scraping every Top100 report into dataframes\npipeline_url = \"http://m.mlb.com/gen/players/prospects/2014/\"\nprospect_url_list_2014 = []\nlink_status_2014 = []\n#making links\nfor i in player_ids_2014:\n    prospect_url = pipeline_url + i + '.json'\n    prospect_url_list_2014.append(prospect_url)\n\n#testing links\nfor i in prospect_url_list_2014:    \n    response = requests.get(i)\n    if response.status_code == 200:\n        link = 'Link is working'\n    else:\n        link = 'Link does not work'\n    link_status_2014.append(link)\n    \n#making initial list of player scout-reports/cards\ncard_list_2014 = []\nfor i in prospect_url_list_2014:    \n    response = requests.get(i)\n    player_card_framed = response.json()\n    player_card = player_card_framed['prospect_player']\n    player_card\n    player_report_and_video = player_card['content']\n    player_report = player_report_and_video['default']\n    card_list_2014.append(player_report)\n\n\n\nreport_trim_1_list_2014 = []\nfor i in card_list_2014:\n    trim = i.rfind('Overall: ') + 10\n    report_trim_1 = i[trim:]\n    report_trim_1_list_2014.append(report_trim_1)\n\nreport_cleaner_list_2014 = []\nfor i in report_trim_1_list_2014:\n    if i.find('</a>') == -1:\n        start = i.find('n<p>') + 3\n    else:\n        start = i.find('</a>') + 8\n    trim_a = i[start:]\n    report_cleaner_list_2014.append(trim_a)\n\nreports_2014 = []\nfor i in report_cleaner_list_2014:\n    without_p = i.replace('<p>', '')\n    without_p2 = without_p.replace('p>', '')\n    without_n = without_p2.replace('\\n', '')\n    without_slash = without_n.replace('/', '')\n    lowered = without_slash.lower()\n    reports_2014.append(lowered)\n\nplayer_id_dataframe_2014['Written Report'] = reports_2014\ntop_one_hundred_data_2014 = player_id_dataframe_2014\n\nfull_scores = []\n\nfor i in reports_2014:\n    \n    text = TextBlob(i)\n   \n    score = text.sentiment\n    \n    full_scores.append(score)\n\nfull_scores\n\ntop_one_hundred_data_2014['Sentiment Score'] = full_scores\n\nsorted_2014 = top_one_hundred_data_2014.sort_values(by=['Sentiment Score'],ascending = False)\n\n\nsorted_2014 = sorted_2014.drop(['Written Report', 'Player ID'], axis = 1)\n\n###2016\n\n###Part 1: scraping initial 2016 mlb pipeline json file for player ID dataframe\n\n#making initial broad datarfame\nmlb_json_id_url_2016 = 'http://m.mlb.com/gen/players/prospects/2016/playerProspects.json'\nresponse_2016 = requests.get(mlb_json_id_url_2016)\nresponse_2016.status_code\nall_json_2016 = response_2016.json()\nprospect_list_2016 = all_json_2016['prospect_players']['prospects']\nplayer_ids_2016 = []\nplayer_ranks_2016 = []\nplayer_first_name_2016 = []\nplayer_last_name_2016 = []\nplayer_position_2016 = []\nplayer_team_2016 = []\nfor i in prospect_list_2016:\n    player_id = str(i['player_id'])\n    player_ids_2016.append(player_id)                      \n    rank = i[\"rank\"]\n    player_ranks_2016.append(rank)\n    first_name = i[\"player_first_name\"]\n    player_first_name_2016.append(first_name)\n    last_name = i[\"player_last_name\"]\n    player_last_name_2016.append(last_name)\n    position = i[\"position\"]\n    player_position_2016.append(position)\n    team = i[\"team_file_code\"]\n    player_team_2016.append(team)\n    player_id_data_2016 = {'First Name' : player_first_name_2016, 'Last Name' : player_last_name_2016, 'Player ID' : player_ids_2016, 'Team' : player_team_2016, 'Position' : player_position_2016, 'Player Rank' : player_ranks_2016}\n\n\nplayer_id_dataframe_2016 = pd.DataFrame(player_id_data_2016)\n\n\n###Part 3: Scraping every Top100 report into dataframes\npipeline_url = \"http://m.mlb.com/gen/players/prospects/2016/\"\nprospect_url_list_2016 = []\nlink_status_2016 = []\n#making links\nfor i in player_ids_2016:\n    prospect_url = pipeline_url + i + '.json'\n    prospect_url_list_2016.append(prospect_url)\n\n#testing links\nfor i in prospect_url_list_2016:    \n    response = requests.get(i)\n    if response.status_code == 200:\n        link = 'Link is working'\n    else:\n        link = 'Link does not work'\n    link_status_2016.append(link)\n    \n#making initial list of player scout-reports/cards\ncard_list_2016 = []\nfor i in prospect_url_list_2016:    \n    response = requests.get(i)\n    player_card_framed = response.json()\n    player_card = player_card_framed['prospect_player']\n    player_card\n    player_report_and_video = player_card['content']\n    player_report = player_report_and_video['default']\n    card_list_2016.append(player_report)\n\n\n\nreport_trim_1_list_2016 = []\nfor i in card_list_2016:\n    trim = i.rfind('Overall: ') + 10\n    report_trim_1 = i[trim:]\n    report_trim_1_list_2016.append(report_trim_1)\n\nreport_cleaner_list_2016 = []\nfor i in report_trim_1_list_2016:\n    if i.find('</a>') == -1:\n        start = i.find('n<p>') + 3\n    else:\n        start = i.find('</a>') + 8\n    trim_a = i[start:]\n    report_cleaner_list_2016.append(trim_a)\n\nreports_2016 = []\nfor i in report_cleaner_list_2016:\n    without_p = i.replace('<p>', '')\n    without_p2 = without_p.replace('p>', '')\n    without_n = without_p2.replace('\\n', '')\n    lowered = without_n.lower()\n    reports_2016.append(lowered)\n\nplayer_id_dataframe_2016['Written Report'] = reports_2016\ntop_one_hundred_data_2016 = player_id_dataframe_2016\n\nfull_scores = []\n\nfor i in reports_2016:\n    \n    text = TextBlob(i)\n   \n    score = text.sentiment\n    \n    full_scores.append(score)\n\nfull_scores\n\ntop_one_hundred_data_2016['Sentiment Score'] = full_scores\n\nsorted_2016 = top_one_hundred_data_2016.sort_values(by=['Sentiment Score'],ascending = False)\n\n\nsorted_2016 = sorted_2016.drop(['Written Report', 'Player ID'], axis = 1)\n\n\n\n###2017\n\n###Part 1: scraping initial 2017 mlb pipeline json file for player ID dataframe\n\n#making initial broad datarfame\nmlb_json_id_url_2017 = 'http://m.mlb.com/gen/players/prospects/2017/playerProspects.json'\nresponse_2017 = requests.get(mlb_json_id_url_2017)\nresponse_2017.status_code\nall_json_2017 = response_2017.json()\nprospect_list_2017 = all_json_2017['prospect_players']['prospects']\nplayer_ids_2017 = []\nplayer_ranks_2017 = []\nplayer_first_name_2017 = []\nplayer_last_name_2017 = []\nplayer_position_2017 = []\nplayer_team_2017 = []\nfor i in prospect_list_2017:\n    player_id = str(i['player_id'])\n    player_ids_2017.append(player_id)                      \n    rank = i[\"rank\"]\n    player_ranks_2017.append(rank)\n    first_name = i[\"player_first_name\"]\n    player_first_name_2017.append(first_name)\n    last_name = i[\"player_last_name\"]\n    player_last_name_2017.append(last_name)\n    position = i[\"position\"]\n    player_position_2017.append(position)\n    team = i[\"team_file_code\"]\n    player_team_2017.append(team)\n    player_id_data_2017 = {'First Name' : player_first_name_2017, 'Last Name' : player_last_name_2017, 'Player ID' : player_ids_2017, 'Team' : player_team_2017, 'Position' : player_position_2017, 'Player Rank' : player_ranks_2017}\n\n\nplayer_id_dataframe_2017 = pd.DataFrame(player_id_data_2017)\n\n\n###Part 3: Scraping every Top100 report into dataframes\npipeline_url = \"http://m.mlb.com/gen/players/prospects/2017/\"\nprospect_url_list_2017 = []\nlink_status_2017 = []\n#making links\nfor i in player_ids_2017:\n    prospect_url = pipeline_url + i + '.json'\n    prospect_url_list_2017.append(prospect_url)\n\n#testing links\nfor i in prospect_url_list_2017:    \n    response = requests.get(i)\n    if response.status_code == 200:\n        link = 'Link is working'\n    else:\n        link = 'Link does not work'\n    link_status_2017.append(link)\n    \n#making initial list of player scout-reports/cards\ncard_list_2017 = []\nfor i in prospect_url_list_2017:    \n    response = requests.get(i)\n    player_card_framed = response.json()\n    player_card = player_card_framed['prospect_player']\n    player_card\n    player_report_and_video = player_card['content']\n    player_report = player_report_and_video['default']\n    card_list_2017.append(player_report)\n\n\n\nreport_trim_1_list_2017 = []\nfor i in card_list_2017:\n    trim = i.rfind('Overall: ') + 10\n    report_trim_1 = i[trim:]\n    report_trim_1_list_2017.append(report_trim_1)\n\nreport_cleaner_list_2017 = []\nfor i in report_trim_1_list_2017:\n    if i.find('</a>') == -1:\n        start = i.find('n<p>') + 3\n    else:\n        start = i.find('</a>') + 8\n    trim_a = i[start:]\n    report_cleaner_list_2017.append(trim_a)\n\nreports_2017 = []\nfor i in report_cleaner_list_2017:\n    without_p = i.replace('<p>', '')\n    without_p2 = without_p.replace('p>', '')\n    without_n = without_p2.replace('\\n', '')\n    lowered = without_n.lower()\n    reports_2017.append(lowered)\n\nplayer_id_dataframe_2017['Written Report'] = reports_2017\ntop_one_hundred_data_2017 = player_id_dataframe_2017\n\nfull_scores = []\n\nfor i in reports_2017:\n    \n    text = TextBlob(i)\n   \n    score = text.sentiment\n    \n    full_scores.append(score)\n\nfull_scores\n\ntop_one_hundred_data_2017['Sentiment Score'] = full_scores\n\nsorted_2017 = top_one_hundred_data_2017.sort_values(by=['Sentiment Score'],ascending = False)\n\n\nsorted_2017 = sorted_2017.drop(['Written Report', 'Player ID'], axis = 1)\n\n\n\n###2018\n\n###Part 1: scraping initial 2018 mlb pipeline json file for player ID dataframe\n\n#making initial broad datarfame\nmlb_json_id_url_2018 = 'http://m.mlb.com/gen/players/prospects/2018/playerProspects.json'\nresponse_2018 = requests.get(mlb_json_id_url_2018)\nresponse_2018.status_code\nall_json_2018 = response_2018.json()\nprospect_list_2018 = all_json_2018['prospect_players']['prospects']\nplayer_ids_2018 = []\nplayer_ranks_2018 = []\nplayer_first_name_2018 = []\nplayer_last_name_2018 = []\nplayer_position_2018 = []\nplayer_team_2018 = []\nfor i in prospect_list_2018:\n    player_id = str(i['player_id'])\n    player_ids_2018.append(player_id)                      \n    rank = i[\"rank\"]\n    player_ranks_2018.append(rank)\n    first_name = i[\"player_first_name\"]\n    player_first_name_2018.append(first_name)\n    last_name = i[\"player_last_name\"]\n    player_last_name_2018.append(last_name)\n    position = i[\"position\"]\n    player_position_2018.append(position)\n    team = i[\"team_file_code\"]\n    player_team_2018.append(team)\n    player_id_data_2018 = {'First Name' : player_first_name_2018, 'Last Name' : player_last_name_2018, 'Player ID' : player_ids_2018, 'Team' : player_team_2018, 'Position' : player_position_2018, 'Player Rank' : player_ranks_2018}\n\n\nplayer_id_dataframe_2018 = pd.DataFrame(player_id_data_2018)\n\n\n###Part 3: Scraping every Top100 report into dataframes\npipeline_url = \"http://m.mlb.com/gen/players/prospects/2018/\"\nprospect_url_list_2018 = []\nlink_status_2018 = []\n#making links\nfor i in player_ids_2018:\n    prospect_url = pipeline_url + i + '.json'\n    prospect_url_list_2018.append(prospect_url)\n\n#testing links\nfor i in prospect_url_list_2018:    \n    response = requests.get(i)\n    if response.status_code == 200:\n        link = 'Link is working'\n    else:\n        link = 'Link does not work'\n    link_status_2018.append(link)\n    \n#making initial list of player scout-reports/cards\ncard_list_2018 = []\nfor i in prospect_url_list_2018:    \n    response = requests.get(i)\n    player_card_framed = response.json()\n    player_card = player_card_framed['prospect_player']\n    player_card\n    player_report_and_video = player_card['content']\n    player_report = player_report_and_video['default']\n    card_list_2018.append(player_report)\n\n\n\nreport_trim_1_list_2018 = []\nfor i in card_list_2018:\n    trim = i.rfind('Overall: ') + 10\n    report_trim_1 = i[trim:]\n    report_trim_1_list_2018.append(report_trim_1)\n\nreport_cleaner_list_2018 = []\nfor i in report_trim_1_list_2018:\n    if i.find('</a>') == -1:\n        start = i.find('n<p>') + 3\n    else:\n        start = i.find('</a>') + 8\n    trim_a = i[start:]\n    report_cleaner_list_2018.append(trim_a)\n\nreports_2018 = []\nfor i in report_cleaner_list_2018:\n    without_p = i.replace('<p>', '')\n    without_p2 = without_p.replace('p>', '')\n    without_n = without_p2.replace('\\n', '')\n    lowered = without_n.lower()\n    reports_2018.append(lowered)\n\nplayer_id_dataframe_2018['Written Report'] = reports_2018\ntop_one_hundred_data_2018 = player_id_dataframe_2018\n\nfull_scores = []\n\nfor i in reports_2018:\n    \n    text = TextBlob(i)\n   \n    score = text.sentiment\n    \n    full_scores.append(score)\n\nfull_scores\n\ntop_one_hundred_data_2018['Sentiment Score'] = full_scores\n\nsorted_2018 = top_one_hundred_data_2018.sort_values(by=['Sentiment Score'],ascending = False)\n\n\nsorted_2018 = sorted_2018.drop(['Written Report', 'Player ID'], axis = 1)\n\n\n###2019\n\n###Part 1: scraping initial 2019 mlb pipeline json file for player ID dataframe\n#making initial broad datarfame\nmlb_json_id_url_2019 = 'http://m.mlb.com/gen/players/prospects/2019/playerProspects.json'\nresponse_2019 = requests.get(mlb_json_id_url_2019)\nresponse_2019.status_code\nall_json_2019 = response_2019.json()\nprospect_list_2019 = all_json_2019['prospect_players']['prospects']\nplayer_ids_2019 = []\nplayer_ranks_2019 = []\nplayer_first_name_2019 = []\nplayer_last_name_2019 = []\nplayer_position_2019 = []\nplayer_team_2019 = []\nfor i in prospect_list_2019:\n    player_id = str(i['player_id'])\n    player_ids_2019.append(player_id)                      \n    rank = i[\"rank\"]\n    player_ranks_2019.append(rank)\n    first_name = i[\"player_first_name\"]\n    player_first_name_2019.append(first_name)\n    last_name = i[\"player_last_name\"]\n    player_last_name_2019.append(last_name)\n    position = i[\"position\"]\n    player_position_2019.append(position)\n    team = i[\"team_file_code\"]\n    player_team_2019.append(team)\n    player_id_data_2019 = {'First Name' : player_first_name_2019, 'Last Name' : player_last_name_2019, 'Player ID' : player_ids_2019, 'Team' : player_team_2019, 'Position' : player_position_2019, 'Player Rank' : player_ranks_2019}\n\n\nplayer_id_dataframe_2019 = pd.DataFrame(player_id_data_2019)\n\n\n###Part 3: Scraping every Top100 report into dataframes\npipeline_url = \"http://m.mlb.com/gen/players/prospects/2019/\"\nprospect_url_list_2019 = []\nlink_status_2019 = []\n#making links\nfor i in player_ids_2019:\n    prospect_url = pipeline_url + i + '.json'\n    prospect_url_list_2019.append(prospect_url)\n\n#testing links\nfor i in prospect_url_list_2019:    \n    response = requests.get(i)\n    if response.status_code == 200:\n        link = 'Link is working'\n    else:\n        link = 'Link does not work'\n    link_status_2019.append(link)\n    \n#making initial list of player scout-reports/cards\ncard_list_2019 = []\nfor i in prospect_url_list_2019:    \n    response = requests.get(i)\n    player_card_framed = response.json()\n    player_card = player_card_framed['prospect_player']\n    player_card\n    player_report_and_video = player_card['content']\n    player_report = player_report_and_video['default']\n    card_list_2019.append(player_report)\n\n\n\nreport_trim_1_list_2019 = []\nfor i in card_list_2019:\n    trim = i.rfind('Overall: ') + 10\n    report_trim_1 = i[trim:]\n    report_trim_1_list_2019.append(report_trim_1)\n\nreport_cleaner_list_2019 = []\nfor i in report_trim_1_list_2019:\n    if i.find('</a>') == -1:\n        start = i.find('n<p>') + 3\n    else:\n        start = i.find('</a>') + 8\n    trim_a = i[start:]\n    report_cleaner_list_2019.append(trim_a)\n\nreports_2019 = []\nfor i in report_cleaner_list_2019:\n    without_p = i.replace('<p>', '')\n    without_p2 = without_p.replace('p>', '')\n    without_n = without_p2.replace('\\n', '')\n    lowered = without_n.lower()\n    reports_2019.append(lowered)\n\nplayer_id_dataframe_2019['Written Report'] = reports_2019\ntop_one_hundred_data_2019 = player_id_dataframe_2019\n\nfull_scores = []\n\nfor i in reports_2019:\n    \n    text = TextBlob(i)\n   \n    score = text.sentiment\n    \n    full_scores.append(score)\n\nfull_scores\n\ntop_one_hundred_data_2019['Sentiment Score'] = full_scores\n\nsorted_2019 = top_one_hundred_data_2019.sort_values(by=['Sentiment Score'],ascending = False)\n\n\nsorted_2019 = sorted_2019.drop(['Written Report', 'Player ID'], axis = 1)\n\n\n#2020\n###Part 1: scraping initial 2020 mlb pipeline json file for player ID dataframe\n#making initial broad datarfame\nmlb_json_id_url_2020 = 'http://m.mlb.com/gen/players/prospects/2020/playerProspects.json'\nresponse_2020 = requests.get(mlb_json_id_url_2020)\nresponse_2020.status_code\nall_json_2020 = response_2020.json()\nprospect_list_2020 = all_json_2020['prospect_players']['prospects']\nplayer_ids_2020 = []\nplayer_ranks_2020 = []\nplayer_first_name_2020 = []\nplayer_last_name_2020 = []\nplayer_position_2020 = []\nplayer_team_2020 = []\nfor i in prospect_list_2020:\n    player_id = str(i['player_id'])\n    player_ids_2020.append(player_id)                      \n    rank = i[\"rank\"]\n    player_ranks_2020.append(rank)\n    first_name = i[\"player_first_name\"]\n    player_first_name_2020.append(first_name)\n    last_name = i[\"player_last_name\"]\n    player_last_name_2020.append(last_name)\n    position = i[\"position\"]\n    player_position_2020.append(position)\n    team = i[\"team_file_code\"]\n    player_team_2020.append(team)\n    player_id_data_2020 = {'First Name' : player_first_name_2020, 'Last Name' : player_last_name_2020, 'Player ID' : player_ids_2020, 'Team' : player_team_2020, 'Position' : player_position_2020, 'Player Rank' : player_ranks_2020}\n\n\nplayer_id_dataframe_2020 = pd.DataFrame(player_id_data_2020)\n\n\n###Part 3: Scraping every Top100 report into dataframes\npipeline_url = \"http://m.mlb.com/gen/players/prospects/2020/\"\nprospect_url_list_2020 = []\nlink_status_2020 = []\n#making links\nfor i in player_ids_2020:\n    prospect_url = pipeline_url + i + '.json'\n    prospect_url_list_2020.append(prospect_url)\n\n#testing links\nfor i in prospect_url_list_2020:    \n    response = requests.get(i)\n    if response.status_code == 200:\n        link = 'Link is working'\n    else:\n        link = 'Link does not work'\n    link_status_2020.append(link)\n    \n#making initial list of player scout-reports/cards\ncard_list_2020 = []\nfor i in prospect_url_list_2020:    \n    response = requests.get(i)\n    player_card_framed = response.json()\n    player_card = player_card_framed['prospect_player']\n    player_card\n    player_report_and_video = player_card['content']\n    player_report = player_report_and_video['default']\n    card_list_2020.append(player_report)\n\n\n\nreport_trim_1_list_2020 = []\nfor i in card_list_2020:\n    trim = i.rfind('Overall: ') + 10\n    report_trim_1 = i[trim:]\n    report_trim_1_list_2020.append(report_trim_1)\n\nreport_cleaner_list_2020 = []\nfor i in report_trim_1_list_2020:\n    if i.find('</a>') == -1:\n        start = i.find('n<p>') + 3\n    else:\n        start = i.find('</a>') + 8\n    trim_a = i[start:]\n    report_cleaner_list_2020.append(trim_a)\n\nreports_2020 = []\nfor i in report_cleaner_list_2020:\n    without_p = i.replace('<p>', '')\n    without_p2 = without_p.replace('p>', '')\n    without_n = without_p2.replace('\\n', '')\n    lowered = without_n.lower()\n    reports_2020.append(lowered)\n\nplayer_id_dataframe_2020['Written Report'] = reports_2020\ntop_one_hundred_data_2020 = player_id_dataframe_2020\n\nfull_scores = []\n\nfor i in reports_2020:\n    \n    text = TextBlob(i)\n   \n    score = text.sentiment\n    \n    full_scores.append(score)\n\nfull_scores\n\ntop_one_hundred_data_2020['Sentiment Score'] = full_scores\n\nsorted_2020 = top_one_hundred_data_2020.sort_values(by=['Sentiment Score'],ascending = False)\n\n\nsorted_2020 = sorted_2020.drop(['Written Report', 'Player ID'], axis = 1)\n\nsorted_2020.index.name = '2020 MILB 100'\nsorted_2019.index.name = '2019 MILB 100'\nsorted_2018.index.name = '2018 MILB 100'\nsorted_2017.index.name = '2017 MILB 100'\nsorted_2016.index.name = '2016 MILB 100'\nsorted_2014.index.name = '2014 MILB 100'\nsorted_2013.index.name = '2013 MILB 100'\nprint('2020 Top 100 MILB Sorted by Sentiment Analysis'), sorted_2020, print('2019 Top 100 MILB Prospects Sorted by Sentiment Analysis'), sorted_2019, print('2018 Top 100 MILB Prospects Sorted by Sentiment Analysis'), sorted_2018, print('2017 Top 100 MILB Prospects Sorted by Sentiment Analysis'), sorted_2017, print('2016 Top 100 MILB Prospects Sorted by Sentiment Analysis'), sorted_2016, print('2014 Top 100 MILB Prospects Sorted by Sentiment Analysis'), sorted_2014, print('2013 Top 100 MILB Prospects Sorted by Sentiment Analysis'), sorted_2013",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}